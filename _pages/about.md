---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a third-year PhD student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.

My current research focuses on unified multimodal models. Feel free to contact me via email at [jzhan24@m.fudan.edu.cn](jzhan24@m.fudan.edu.cn).

# ğŸ”¥ News
- *2024.09*: &nbsp;ğŸ“ I became a phd student at FudanNLPLab.
- *2024.07*: &nbsp;ğŸ¤– We released [SpeechGPT2](https://0nutation.github.io/SpeechGPT2.github.io/), a emotional intelligent end-to-end spoken dialogue LLM.
- *2024.05*: &nbsp;ğŸ‰ One first-author paper accepted to ACL 2024!
- *2024.03*: &nbsp;ğŸ¤– We release the model, data, and code of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!
- *2023.05*: &nbsp;ğŸ¤– We released [SpeechGPT](https://0nutation.github.io/SpeechGPT.github.io/), a conversational speech large language model.
- *2022.09*: &nbsp;ğŸ“ I joined FudanNLPLab as a master student.


# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2024</div><img src='images/anygpt-model1.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/pdf/2402.12226.pdf) \\
**Jun Zhan**, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, Yugang Jiang1, Xipeng Qiu

[**Project**](https://junzhan2000.github.io/AnyGPT.github.io/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>
- **Role**: Project Lead
- AnyGPT is the first any-to-any multimodal LLM based on discrete representations.
- **Academic Impact**: This work has received 800+ stars on GitHub, promoted by more than 10 media and forums, such as [æœºå™¨ä¹‹å¿ƒ](https://www.jiqizhixin.com/articles/2024-03-04-10)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2023</div><img src='images/speechgpt-model2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities](https://arxiv.org/pdf/2305.11000.pdf) \\
Dong Zhang, Shimin Li, Xin Zhang, **Jun Zhan**, Pengyu Wang, Yaqian Zhou, Xipeng Qiu

[**Project**](https://0nutation.github.io/SpeechGPT.github.io/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- SpeechGPT is the first LLM with intrinsic cross-modal generation abilities.
- **Academic Impact**: This work has received 1.3k+ stars on [GitHub](https://github.com/0nutation/SpeechGPT/tree/main/speechgpt), promoted by more than 10 media and forums, such as [æœºå™¨ä¹‹å¿ƒ](https://m.thepaper.cn/newsDetail_forward_23161170)
</div>
</div>



# ğŸ› ï¸ Projects

<!-- <div class='paper-box'><div class='paper-box-image'><img src='images/moss.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->


<div class='paper-box'><div class='paper-box-image'><div><img src='images/moss.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MOSS: A Conversational Language Model](https://github.com/OpenMOSS/MOSS) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>
- Tianxiang Sun, Xiaotian Zhang, Zhengfu He, Peng Li, Qinyuan Cheng, Hang Yan, Xiangyang Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke Chen, Yining Zheng, Zhejian Zhou, Ruixiao Li, **Jun Zhan**, Yunhua Zhou, Linyang Li, Xiaogui Yang, Lingling Wu, Zhangyue Yin, Xuanjing Huang, Xipeng Qiu.
- ğŸŒŸ MOSS is the first ChatGPT-like LLM in China, and fully open sourced with 12k+ stars. [GitHub](https://github.com/OpenMOSS/MOSS)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/speechgpt2-model.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SpeechGPT2:
End-to-End Human-Like Spoken Chatbot](https://0nutation.github.io/SpeechGPT2.github.io/)
- Dong Zhang, Qian Tu*, Ruifan Deng*, **Jun Zhan\***, Zixin Wang*, Xingjian Zhao, Ke Chen, Xin Zhang, Pengyu Wang, Zhaowei Li, Shimin Li, Yaqian Zhou, Xipeng Qiu.
- ğŸŒŸ SpeechGPT2 is a emotional intelligent end-to-end spoken dialogue LLM.
</div>
</div>

# ğŸ– Honors and Awards
- *2024.08*: ğŸ˜„ The Best Poster at the 3rd HIT-SCIR \& THUNLP \& FudanNLP Academic Symposium.
- *2024.12*: âš½ï¸ The runner-up of the 2024 Fudan University Graduate Football Tournament.

# ğŸ“– Educations
- *2024.09 - (now)*, Phd, Fudan University, Shanghai.
- *2022.09 - 2024.06*, Master, Fudan University, Shanghai.
- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.
