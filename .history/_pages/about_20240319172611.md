---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a second-year Master's student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.

My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at [jzhan22@m.fudan.edu.cn](jzhan22@m.fudan.edu.cn).

# üî• News
- *2024.03*: &nbsp;üéâüéâ We release the data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!
- *2024.02*: &nbsp;ü§ñü§ñ We release the paper of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/).

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/pdf/2402.12226.pdf) \\
**Jun Zhan**, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, Yugang Jiang1, Xipeng Qiu

[**Project**](https://junzhan2000.github.io/AnyGPT.github.io/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- AnyGPT is the first any-to-any multimodal LLM based on discrete representations.
- **Academic Impact**: This work has received 350+ stars on GitHub, promoted by more than 10 media and forums, such as [Êú∫Âô®‰πãÂøÉ](https://www.jiqizhixin.com/articles/2024-03-04-10)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2023</div><img src='images/speechgpt-model2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities](https://arxiv.org/pdf/2305.11000.pdf) \\
Dong Zhang, Shimin Li, Xin Zhang, **Jun Zhan**, Pengyu Wang, Yaqian Zhou, Xipeng Qiu

[**Project**](https://0nutation.github.io/SpeechGPT.github.io/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- SpeechGPT is the first LLM with intrinsic cross-modal generation abilities.
- **Academic Impact**: This work has received 800+ stars on [GitHub](https://github.com/0nutation/SpeechGPT/tree/main/speechgpt), promoted by more than 10 media and forums, such as [Êú∫Âô®‰πãÂøÉ](https://m.thepaper.cn/newsDetail_forward_23161170)
</div>
</div>



# üõ†Ô∏è Projects

<!-- <div class='paper-box'><div class='paper-box-image'><img src='images/moss.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->


<div class='paper-box'><div class='paper-box-image'><div><img src='images/moss.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MOSS: A Conversational Language Model](https://github.com/OpenMOSS/MOSS) \\ <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>
- Tianxiang Sun, Xiaotian Zhang, Zhengfu He, Peng Li, Qinyuan Cheng, Hang Yan, Xiangyang Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke Chen, Yining Zheng, Zhejian Zhou, Ruixiao Li, **Jun Zhan**, Yunhua Zhou, Linyang Li, Xiaogui Yang, Lingling Wu, Zhangyue Yin, Xuanjing Huang, Xipeng Qiu.
- MOSS is a conversational language model like ChatGPT. It is capable of following users' instructions to perform various natural language tasks including question answering, generating text, summarzing text, generating code, etc. MOSS is also able to challenge incorrect premises, and reject inappropriate requests.
- **Impact**: This work has received 11.8k stars on [GitHub](https://github.com/OpenMOSS/MOSS)
</div>
</div>


# üìñ Educations
- *2022.09 - (now)*, Master, Fudan University, Shanghai.
- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.