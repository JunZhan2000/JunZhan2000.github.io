---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a second-year Master's student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.

My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at [jzhan22@m.fudan.edu.cn](jzhan22@m.fudan.edu.cn).

# 🔥 News
- *2024.03*: &nbsp;🎉🎉 We release the data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!
- *2024.02*: &nbsp;🤖🤖 We release the paper of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/).

# 📝 Publications 

<div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/pdf/2402.12226.pdf) \\
**Jun Zhan**, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, Yugang Jiang1, Xipeng Qiu

[**Project**](https://junzhan2000.github.io/AnyGPT.github.io/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- AnyGPT is the first any-to-any multimodal LLM based on discrete representations.
- **Academic Impact**: This work has received 350+ stars on GitHub, promoted by more than 10 media and forums, such as [机器之心](https://www.jiqizhixin.com/articles/2024-03-04-10)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2023</div><img src='images/speechgpt-model2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities](https://arxiv.org/pdf/2305.11000.pdf) \\
Dong Zhang, Shimin Li, Xin Zhang, **Jun Zhan**, Pengyu Wang, Yaqian Zhou, Xipeng Qiu

[**Project**](https://0nutation.github.io/SpeechGPT.github.io/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- SpeechGPT is the first LLM with intrinsic cross-modal generation abilities.
- **Academic Impact**: This work has received 800+ stars on [GitHub](https://github.com/0nutation/SpeechGPT/tree/main/speechgpt), promoted by more than 10 media and forums, such as [机器之心](https://m.thepaper.cn/newsDetail_forward_23161170)
</div>
</div>



# 🛠️ Projects

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2023</div><img src='images/speechgpt-model2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities](https://arxiv.org/pdf/2305.11000.pdf) \\
Dong Zhang, Shimin Li, Xin Zhang, **Jun Zhan**, Pengyu Wang, Yaqian Zhou, Xipeng Qiu

[**Project**](https://0nutation.github.io/SpeechGPT.github.io/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- SpeechGPT is the first LLM with intrinsic cross-modal generation abilities.
- **Academic Impact**: This work has received 800+ stars on [GitHub](https://github.com/0nutation/SpeechGPT/tree/main/speechgpt), promoted by more than 10 media and forums, such as [机器之心](https://m.thepaper.cn/newsDetail_forward_23161170)
</div>
</div>


# 📖 Educations
- *2022.09 - (now)*, Master, Fudan University, Shanghai.
- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.