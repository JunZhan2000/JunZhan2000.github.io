{
    "sourceFile": "_pages/about.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 7,
            "patches": [
                {
                    "date": 1710762905413,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1710762931397,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,11 +20,8 @@\n I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n \n My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n \n-My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src=\"https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations\"></a>).\n-\n-\n # ğŸ”¥ News\n - *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n \n"
                },
                {
                    "date": 1710763058310,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,57 @@\n+---\n+permalink: /\n+title: \"\"\n+excerpt: \"\"\n+author_profile: true\n+redirect_from: \n+  - /about/\n+  - /about.html\n+---\n+\n+{% if site.google_scholar_stats_use_cdn %}\n+{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n+{% else %}\n+{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n+{% endif %}\n+{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n+\n+<span class='anchor' id='about-me'></span>\n+\n+I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n+\n+My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n+\n+# ğŸ”¥ News\n+- *2024.02*: &nbsp;ğŸ‰ğŸ‰ We release the paper, model and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n+. \n+\n+# ğŸ“ Publications \n+\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+\n+**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n+\n+[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+</div>\n+</div>\n+\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n+\n+# ğŸ– Honors and Awards\n+- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+\n+# ğŸ“– Educations\n+- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+\n+# ğŸ’¬ Invited Talks\n+- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n+\n+# ğŸ’» Internships\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710763209174,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,58 @@\n+---\n+permalink: /\n+title: \"\"\n+excerpt: \"\"\n+author_profile: true\n+redirect_from: \n+  - /about/\n+  - /about.html\n+---\n+\n+{% if site.google_scholar_stats_use_cdn %}\n+{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n+{% else %}\n+{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n+{% endif %}\n+{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n+\n+<span class='anchor' id='about-me'></span>\n+\n+I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n+\n+My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n+\n+# ğŸ”¥ News\n+- *2024.02*: &nbsp;ğŸ‰ğŸ‰ We release the paper, model and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n+. \n+\n+# ğŸ“ Publications \n+\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+\n+**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n+\n+[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+</div>\n+</div>\n+\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n+\n+<!-- # ğŸ– Honors and Awards\n+- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n+\n+# ğŸ“– Educations\n+- *2018.06 - (now)*, Master, Fudan University, Shanghai.\n+- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n+\n+\n+# ğŸ’¬ Invited Talks\n+- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n+\n+# ğŸ’» Internships\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710763214844,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -45,128 +45,14 @@\n - *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n \n # ğŸ“– Educations\n-- *2018.06 - (now)*, Master, Fudan University, Shanghai.\n+- *2022.09 - (now)*, Master, Fudan University, Shanghai.\n - *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n \n \n # ğŸ’¬ Invited Talks\n - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n \n # ğŸ’» Internships\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n----\n-permalink: /\n-title: \"\"\n-excerpt: \"\"\n-author_profile: true\n-redirect_from: \n-  - /about/\n-  - /about.html\n----\n-\n-{% if site.google_scholar_stats_use_cdn %}\n-{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n-{% else %}\n-{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n-{% endif %}\n-{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n-\n-<span class='anchor' id='about-me'></span>\n-\n-I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n-\n-My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n-\n-# ğŸ”¥ News\n-- *2024.02*: &nbsp;ğŸ‰ğŸ‰ We release the paper, model and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n-. \n-\n-# ğŸ“ Publications \n-\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n-<div class='paper-box-text' markdown=\"1\">\n-\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n-\n-**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n-\n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-</div>\n-</div>\n-\n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n-\n-# ğŸ– Honors and Awards\n-- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# ğŸ“– Educations\n-- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# ğŸ’¬ Invited Talks\n-- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n-\n-# ğŸ’» Internships\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n----\n-permalink: /\n-title: \"\"\n-excerpt: \"\"\n-author_profile: true\n-redirect_from: \n-  - /about/\n-  - /about.html\n----\n-\n-{% if site.google_scholar_stats_use_cdn %}\n-{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n-{% else %}\n-{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n-{% endif %}\n-{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n-\n-<span class='anchor' id='about-me'></span>\n-\n-I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n-\n-My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n-\n-# ğŸ”¥ News\n-- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# ğŸ“ Publications \n-\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n-<div class='paper-box-text' markdown=\"1\">\n-\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n-\n-**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n-\n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-</div>\n-</div>\n-\n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n-\n-# ğŸ– Honors and Awards\n-- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# ğŸ“– Educations\n-- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# ğŸ’¬ Invited Talks\n-- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n-\n-# ğŸ’» Internships\n - *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710763221319,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,10 +49,10 @@\n - *2022.09 - (now)*, Master, Fudan University, Shanghai.\n - *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n \n \n-# ğŸ’¬ Invited Talks\n+<!-- # ğŸ’¬ Invited Talks\n - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/) -->\n \n\\ No newline at end of file\n-# ğŸ’» Internships\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n+<!-- # ğŸ’» Internships\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710824568990,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,16 +21,19 @@\n \n My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n \n # ğŸ”¥ News\n-- *2024.02*: &nbsp;ğŸ‰ğŸ‰ We release the paper, model and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n+- *2024.02*: &nbsp;ğŸ‰ğŸ‰ We release the paper and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n . \n \n # ğŸ“ Publications \n \n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n+<div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n [Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n \n **Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n \n"
                },
                {
                    "date": 1710824575968,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,8 +29,10 @@\n \n <div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+\n <div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n [Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n"
                }
            ],
            "date": 1710762905413,
            "name": "Commit-0",
            "content": "---\npermalink: /\ntitle: \"\"\nexcerpt: \"\"\nauthor_profile: true\nredirect_from: \n  - /about/\n  - /about.html\n---\n\n{% if site.google_scholar_stats_use_cdn %}\n{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n{% else %}\n{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n{% endif %}\n{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n\n<span class='anchor' id='about-me'></span>\n\nI am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n\nMy current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n\nMy research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src=\"https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations\"></a>).\n\n\n# ğŸ”¥ News\n- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n\n# ğŸ“ Publications \n\n<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n<div class='paper-box-text' markdown=\"1\">\n\n[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n\n**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n\n[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n</div>\n</div>\n\n- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n\n# ğŸ– Honors and Awards\n- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n\n# ğŸ“– Educations\n- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n\n# ğŸ’¬ Invited Talks\n- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n\n# ğŸ’» Internships\n- *2019.05 - 2020.02*, [Lorem](https://github.com/), China."
        }
    ]
}