{
    "sourceFile": "_pages/about.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 14,
            "patches": [
                {
                    "date": 1710762905413,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1710762931397,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,11 +20,8 @@\n I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n \n My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n \n-My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src=\"https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations\"></a>).\n-\n-\n # üî• News\n - *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n \n"
                },
                {
                    "date": 1710763058310,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,57 @@\n+---\n+permalink: /\n+title: \"\"\n+excerpt: \"\"\n+author_profile: true\n+redirect_from: \n+  - /about/\n+  - /about.html\n+---\n+\n+{% if site.google_scholar_stats_use_cdn %}\n+{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n+{% else %}\n+{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n+{% endif %}\n+{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n+\n+<span class='anchor' id='about-me'></span>\n+\n+I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n+\n+My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n+\n+# üî• News\n+- *2024.02*: &nbsp;üéâüéâ We release the paper, model and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n+. \n+\n+# üìù Publications \n+\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+\n+**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n+\n+[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+</div>\n+</div>\n+\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n+\n+# üéñ Honors and Awards\n+- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+\n+# üìñ Educations\n+- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+\n+# üí¨ Invited Talks\n+- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n+\n+# üíª Internships\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710763209174,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,58 @@\n+---\n+permalink: /\n+title: \"\"\n+excerpt: \"\"\n+author_profile: true\n+redirect_from: \n+  - /about/\n+  - /about.html\n+---\n+\n+{% if site.google_scholar_stats_use_cdn %}\n+{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n+{% else %}\n+{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n+{% endif %}\n+{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n+\n+<span class='anchor' id='about-me'></span>\n+\n+I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n+\n+My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n+\n+# üî• News\n+- *2024.02*: &nbsp;üéâüéâ We release the paper, model and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n+. \n+\n+# üìù Publications \n+\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+\n+**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n+\n+[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+</div>\n+</div>\n+\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n+\n+<!-- # üéñ Honors and Awards\n+- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n+\n+# üìñ Educations\n+- *2018.06 - (now)*, Master, Fudan University, Shanghai.\n+- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n+\n+\n+# üí¨ Invited Talks\n+- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n+\n+# üíª Internships\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710763214844,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -45,128 +45,14 @@\n - *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n \n # üìñ Educations\n-- *2018.06 - (now)*, Master, Fudan University, Shanghai.\n+- *2022.09 - (now)*, Master, Fudan University, Shanghai.\n - *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n \n \n # üí¨ Invited Talks\n - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n \n # üíª Internships\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n----\n-permalink: /\n-title: \"\"\n-excerpt: \"\"\n-author_profile: true\n-redirect_from: \n-  - /about/\n-  - /about.html\n----\n-\n-{% if site.google_scholar_stats_use_cdn %}\n-{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n-{% else %}\n-{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n-{% endif %}\n-{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n-\n-<span class='anchor' id='about-me'></span>\n-\n-I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n-\n-My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n-\n-# üî• News\n-- *2024.02*: &nbsp;üéâüéâ We release the paper, model and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n-. \n-\n-# üìù Publications \n-\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n-<div class='paper-box-text' markdown=\"1\">\n-\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n-\n-**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n-\n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-</div>\n-</div>\n-\n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n-\n-# üéñ Honors and Awards\n-- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# üìñ Educations\n-- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# üí¨ Invited Talks\n-- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n-\n-# üíª Internships\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n----\n-permalink: /\n-title: \"\"\n-excerpt: \"\"\n-author_profile: true\n-redirect_from: \n-  - /about/\n-  - /about.html\n----\n-\n-{% if site.google_scholar_stats_use_cdn %}\n-{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n-{% else %}\n-{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n-{% endif %}\n-{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n-\n-<span class='anchor' id='about-me'></span>\n-\n-I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n-\n-My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n-\n-# üî• News\n-- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# üìù Publications \n-\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n-<div class='paper-box-text' markdown=\"1\">\n-\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n-\n-**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n-\n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-</div>\n-</div>\n-\n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n-\n-# üéñ Honors and Awards\n-- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# üìñ Educations\n-- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-\n-# üí¨ Invited Talks\n-- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n-\n-# üíª Internships\n - *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710763221319,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,10 +49,10 @@\n - *2022.09 - (now)*, Master, Fudan University, Shanghai.\n - *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n \n \n-# üí¨ Invited Talks\n+<!-- # üí¨ Invited Talks\n - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/) -->\n \n\\ No newline at end of file\n-# üíª Internships\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.\n+<!-- # üíª Internships\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710824568990,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,16 +21,19 @@\n \n My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n \n # üî• News\n-- *2024.02*: &nbsp;üéâüéâ We release the paper, model and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n+- *2024.02*: &nbsp;üéâüéâ We release the paper and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n . \n \n # üìù Publications \n \n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n+<div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n [Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n \n **Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n \n"
                },
                {
                    "date": 1710824575968,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,8 +29,10 @@\n \n <div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+\n <div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n [Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n"
                },
                {
                    "date": 1710826339645,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,9 @@\n {% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n \n <span class='anchor' id='about-me'></span>\n \n-I am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n+I am currently a second-year Master's student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n \n My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n \n # üî• News\n"
                },
                {
                    "date": 1710826385291,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n <span class='anchor' id='about-me'></span>\n \n I am currently a second-year Master's student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n \n-My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n+My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at [jzhan22@m.fudan.edu.cn](jzhan22@m.fudan.edu.cn).\n \n # üî• News\n - *2024.02*: &nbsp;üéâüéâ We release the paper and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n . \n"
                },
                {
                    "date": 1710826522649,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,63 @@\n+---\n+permalink: /\n+title: \"\"\n+excerpt: \"\"\n+author_profile: true\n+redirect_from: \n+  - /about/\n+  - /about.html\n+---\n+\n+{% if site.google_scholar_stats_use_cdn %}\n+{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n+{% else %}\n+{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n+{% endif %}\n+{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n+\n+<span class='anchor' id='about-me'></span>\n+\n+I am currently a second-year Master's student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n+\n+My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at [jzhan22@m.fudan.edu.cn](jzhan22@m.fudan.edu.cn).\n+\n+# üî• News\n+- *2024.02*: &nbsp;üéâüéâ We release the paper and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n+. \n+\n+# üìù Publications \n+\n+<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+\n+<div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+\n+**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n+\n+[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+</div>\n+</div>\n+\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n+\n+<!-- # üéñ Honors and Awards\n+- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n+\n+# üìñ Educations\n+- *2022.09 - (now)*, Master, Fudan University, Shanghai.\n+- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n+\n+\n+<!-- # üí¨ Invited Talks\n+- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/) -->\n+\n+<!-- # üíª Internships\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710826548263,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,12 +26,12 @@\n . \n \n # üìù Publications \n \n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n+<!-- <div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->\n \n <div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n@@ -59,68 +59,5 @@\n - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/) -->\n \n <!-- # üíª Internships\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n----\n-permalink: /\n-title: \"\"\n-excerpt: \"\"\n-author_profile: true\n-redirect_from: \n-  - /about/\n-  - /about.html\n----\n-\n-{% if site.google_scholar_stats_use_cdn %}\n-{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n-{% else %}\n-{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n-{% endif %}\n-{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n-\n-<span class='anchor' id='about-me'></span>\n-\n-I am currently a second-year Master's student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n-\n-My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at [jzhan22@m.fudan.edu.cn](jzhan22@m.fudan.edu.cn).\n-\n-# üî• News\n-- *2024.02*: &nbsp;üéâüéâ We release the paper and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n-. \n-\n-# üìù Publications \n-\n-<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n-<div class='paper-box-text' markdown=\"1\">\n-\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n-\n-<div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n-<div class='paper-box-text' markdown=\"1\">\n-\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n-\n-**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n-\n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-</div>\n-</div>\n-\n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n-\n-<!-- # üéñ Honors and Awards\n-- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n-\n-# üìñ Educations\n-- *2022.09 - (now)*, Master, Fudan University, Shanghai.\n-- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n-\n-\n-<!-- # üí¨ Invited Talks\n-- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/) -->\n-\n-<!-- # üíª Internships\n - *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710826792130,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,9 +34,9 @@\n \n <div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n <div class='paper-box-text' markdown=\"1\">\n \n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n+[AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/pdf/2402.12226.pdf)\n \n **Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n \n [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n"
                },
                {
                    "date": 1710826986787,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,63 @@\n+---\n+permalink: /\n+title: \"\"\n+excerpt: \"\"\n+author_profile: true\n+redirect_from: \n+  - /about/\n+  - /about.html\n+---\n+\n+{% if site.google_scholar_stats_use_cdn %}\n+{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n+{% else %}\n+{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n+{% endif %}\n+{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n+\n+<span class='anchor' id='about-me'></span>\n+\n+I am currently a second-year Master's student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n+\n+My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at [jzhan22@m.fudan.edu.cn](jzhan22@m.fudan.edu.cn).\n+\n+# üî• News\n+- *2024.02*: &nbsp;üéâüéâ We release the paper and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n+. \n+\n+# üìù Publications \n+\n+<!-- <div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->\n+\n+<div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n+<div class='paper-box-text' markdown=\"1\">\n+\n+[AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/pdf/2402.12226.pdf)\n+\n+**Jun Zhan1**, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, Yugang Jiang1, Xipeng Qiu\n+\n+[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+</div>\n+</div>\n+\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n+\n+<!-- # üéñ Honors and Awards\n+- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n+\n+# üìñ Educations\n+- *2022.09 - (now)*, Master, Fudan University, Shanghai.\n+- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n+\n+\n+<!-- # üí¨ Invited Talks\n+- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n+- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/) -->\n+\n+<!-- # üíª Internships\n+- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n\\ No newline at end of file\n"
                },
                {
                    "date": 1710827116254,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -38,14 +38,14 @@\n [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/pdf/2402.12226.pdf)\n \n **Jun Zhan1**, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, Yugang Jiang1, Xipeng Qiu\n \n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n+<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n - Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n </div>\n </div>\n \n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n+- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->\n \n <!-- # üéñ Honors and Awards\n - *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n@@ -59,68 +59,5 @@\n - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n - *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/) -->\n \n <!-- # üíª Internships\n-- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n----\n-permalink: /\n-title: \"\"\n-excerpt: \"\"\n-author_profile: true\n-redirect_from: \n-  - /about/\n-  - /about.html\n----\n-\n-{% if site.google_scholar_stats_use_cdn %}\n-{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n-{% else %}\n-{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n-{% endif %}\n-{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n-\n-<span class='anchor' id='about-me'></span>\n-\n-I am currently a second-year Master's student at the Fudan University, NLP Lab, supervised by Prof. [Xipeng Qiu](https://xpqiu.github.io/en.html). I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n-\n-My current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at [jzhan22@m.fudan.edu.cn](jzhan22@m.fudan.edu.cn).\n-\n-# üî• News\n-- *2024.02*: &nbsp;üéâüéâ We release the paper and data of [AnyGPT](https://junzhan2000.github.io/AnyGPT.github.io/). Welcome to STAR and FORK!\n-. \n-\n-# üìù Publications \n-\n-<!-- <div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n-<div class='paper-box-text' markdown=\"1\">\n-\n-[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) -->\n-\n-<div class='paper-box'><div class='paper-box-image'><div><img src='images/anygpt-model1.jpg' alt=\"sym\" width=\"100%\"></div></div>\n-<div class='paper-box-text' markdown=\"1\">\n-\n-[AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/pdf/2402.12226.pdf)\n-\n-**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n-\n-[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-</div>\n-</div>\n-\n-- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n-\n-<!-- # üéñ Honors and Awards\n-- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->\n-\n-# üìñ Educations\n-- *2022.09 - (now)*, Master, Fudan University, Shanghai.\n-- *2018.09 - 2022.06*, Undergraduate, Huazhong University of Science and Technology, Wuhan.\n-\n-\n-<!-- # üí¨ Invited Talks\n-- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n-- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/) -->\n-\n-<!-- # üíª Internships\n - *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->\n\\ No newline at end of file\n"
                }
            ],
            "date": 1710762905413,
            "name": "Commit-0",
            "content": "---\npermalink: /\ntitle: \"\"\nexcerpt: \"\"\nauthor_profile: true\nredirect_from: \n  - /about/\n  - /about.html\n---\n\n{% if site.google_scholar_stats_use_cdn %}\n{% assign gsDataBaseUrl = \"https://cdn.jsdelivr.net/gh/\" | append: site.repository | append: \"@\" %}\n{% else %}\n{% assign gsDataBaseUrl = \"https://raw.githubusercontent.com/\" | append: site.repository | append: \"/\" %}\n{% endif %}\n{% assign url = gsDataBaseUrl | append: \"google-scholar-stats/gs_data_shieldsio.json\" %}\n\n<span class='anchor' id='about-me'></span>\n\nI am currently a second-year Master's student at the NLP Lab at Fudan University, under the guidance of Prof. Xipeng Qiu. I graduated from Huazhong University of Science and Technology with a bachelor's degree in software engineering.\n\nMy current research focuses on unified multimodal LLMs and representation models. Feel free to contact me via email at jzhan22@m.fudan.edu.cn.\n\nMy research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src=\"https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations\"></a>).\n\n\n# üî• News\n- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n\n# üìù Publications \n\n<div class='paper-box'><div class='paper-box-image'><div><div class=\"badge\">CVPR 2016</div><img src='images/500x300.png' alt=\"sym\" width=\"100%\"></div></div>\n<div class='paper-box-text' markdown=\"1\">\n\n[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n\n**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n\n[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>\n- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n</div>\n</div>\n\n- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**\n\n# üéñ Honors and Awards\n- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n\n# üìñ Educations\n- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n\n# üí¨ Invited Talks\n- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. \n- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \\| [\\[video\\]](https://github.com/)\n\n# üíª Internships\n- *2019.05 - 2020.02*, [Lorem](https://github.com/), China."
        }
    ]
}